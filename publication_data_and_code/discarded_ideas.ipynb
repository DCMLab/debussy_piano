{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python3 -m pip install -U pandas plotly nbformat networkx`\n",
    "\n",
    "`pip install \"https://github.com/DCMLab/wavescapes/archive/refs/heads/johannes.zip\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "\n",
    "from etl import get_dfts, get_pickled_magnitude_phase_matrices, get_metadata, get_most_resonant, get_pcms, get_pcvs, test_dict_keys, \\\n",
    "  get_correlations, make_feature_vectors, get_metric, get_most_resonant_penta_dia\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from utils import get_coeff\n",
    "\n",
    "from wavescapes.color import circular_hue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DEBUSSY_REPO = '..'\n",
    "DATA_FOLDER = '~/DATA/debussy_figures/data'\n",
    "DATA_FOLDER = './data'\n",
    "EXAMPLE_FNAME = 'l000_etude'\n",
    "LONG_FORMAT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading metadata\n",
    "Metadata for all pieces contained in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metadata = get_metadata(DEBUSSY_REPO)\n",
    "metadata.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns for ordinal plots\n",
    "\n",
    "Creating a column `years_ordinal` that represents the year of publication as a range of years in which Debussy composed.\n",
    "\n",
    "Also creating a column `years_periods` in which the years of publication are grouped into three periods.\n",
    "\n",
    "Periods:\n",
    "- 1880-1892\n",
    "- 1893-1912\n",
    "- 1913-1917\n",
    "\n",
    "src: the cambridge companion to Debussy (the phases years are not consistent accross all sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_ordinal = {val:idx for idx, val in enumerate(np.sort(metadata.year.unique()))}\n",
    "metadata['years_ordinal'] = metadata.year.apply(lambda x: years_ordinal[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_periods = {}\n",
    "\n",
    "for idx, val in enumerate(np.sort(metadata.year.unique())):\n",
    "    if val < 1893:\n",
    "        years_periods[val] = 0\n",
    "    elif val < 1913:\n",
    "        years_periods[val] = 1\n",
    "    else:\n",
    "        years_periods[val] = 2\n",
    "\n",
    "metadata['years_periods'] = metadata.year.fillna(1880.0).apply(lambda x: years_periods[x])\n",
    "metadata.years_ordinal.head(1),metadata.years_periods.head(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `year` contains composition years as the middle between beginning and end  of the composition span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metadata.year.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series `median_recording` contains median recording times in seconds, retrieved from the Spotify API. the Spotify API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metadata.median_recording.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns mirroring a piece's activity are currently:\n",
    "* `qb_per_minute`: the pieces' lengths (expressed as 'qb' = quarterbeats) normalized by the median recording times; a proxy for the tempo\n",
    "* `sounding_notes_per_minute`: the summed length of all notes normalized by the piece's duration (in minutes)\n",
    "* `sounding_notes_per_qb`: the summed length of all notes normalized by the piece's length (in qb)\n",
    "Other measures of activity could be, for example, 'onsets per beat/second' or 'distinct pitch classes per beat/second'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pitch Class Vectors (PCVs)\n",
    "An `{fname -> pd.DataFrame}` dictionary where each `(NX12)` DataFrame contains the absolute durations (expressed in quarter nots) of the 12 chromatic pitch classes for the `N` slices of length = 1 quarter note that make up the piece `fname`. The IntervalIndex reflects each slice's position in the piece. Set `pandas` to False to retrieve NumPy arrays without the IntervalIndex and column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pcvs = get_pcvs(DEBUSSY_REPO, pandas=True)\n",
    "test_dict_keys(pcvs, metadata)\n",
    "pcvs[EXAMPLE_FNAME].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pitch Class Matrices\n",
    "An `{fname -> np.array}` dictionary where each `(NxNx12)` array contains the aggregated PCVs for all segments that make up a piece. The square matrices contain values only in the upper right triangle, with the lower left beneath the diagonal is filled with zeros. The values are arranged such that row 0 correponds to the original PCV, row 1 the aggregated PCVs for all segments of length = 2 quarter notes, etc. For getting the segment reaching from slice 3 to 5 (including), i.e. length 3, the coordinates are `(2, 5)` (think x = 'length - 1' and y = index of the last slice included). The following example shows the upper left 3x3 submatrix where the first three entries (which are PCVs of size 12) correspond to the first three PCVs above, the first three of the second row to their sums padded with a 0-PCV, and the first three of the third row corresponding to the sum of row 0, padded with another 0-PCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pcms = get_pcms(DEBUSSY_REPO, long=LONG_FORMAT)\n",
    "test_dict_keys(pcms, metadata)\n",
    "pcms[EXAMPLE_FNAME].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Discrete Fourier Transforms\n",
    "`{fname -> np.array}` containing `(NxNx7)` complex matrices. For instance, here's the first element, a size 7 complex vector with DFT coefficients 0 through 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dfts = get_dfts(DEBUSSY_REPO, long=LONG_FORMAT)\n",
    "test_dict_keys(dfts, metadata)\n",
    "dfts[EXAMPLE_FNAME].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the 7 complex numbers as magnitude-phase pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_coeff(dfts[EXAMPLE_FNAME], 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or even as strings where the numbers are rounded and angles are shown in degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_coeff(dfts[EXAMPLE_FNAME], 0, 0, deg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading magnitude-phase matrices\n",
    "`{fname -> np.array}` where each of the `(NxNx6x2)` matrices contains the 6 relevant DFT coefficients converted into magnitude-phase pairs where the magnitudes have undergone at least one normalization, i.e. are all within [0,1]. The files have been pre-computed and are loaded from g-zipped pickled matrices.\n",
    "\n",
    "The parameter `norm_params` can be one or several `(how, indulge)` pairs where `indulge` is a boolean and `how âˆˆ {'0c', 'post_norm', 'max_weighted', 'max'}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "norm_params = ('0c', True)\n",
    "mag_phase_mx_dict = get_pickled_magnitude_phase_matrices(DATA_FOLDER, norm_params=norm_params, long=LONG_FORMAT)\n",
    "test_dict_keys(mag_phase_mx_dict, metadata)\n",
    "mag_phase_mx_dict[EXAMPLE_FNAME].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mpm = mag_phase_mx_dict[EXAMPLE_FNAME]\n",
    "colors = circular_hue(mpm[...,1,:], output_rgba=True, ignore_phase=True)\n",
    "colors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the phases (2nd column) are the same that we inspected above via `get_coeff()` whereas the magnitudes are now normalized by the first (now absent) coefficient 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mag_phase_mx_dict[EXAMPLE_FNAME][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading most resonant DFT coefficients\n",
    "This cell depends on the previously loaded magnitude-phase matrices, i.e. a conscious choice of a normalization method has been made above.\n",
    "\n",
    "`get_most_resonant` returns three `{fname -> nd.array}` dictionaries where for each piece, the three `(NxN)` matrices correspond to\n",
    "\n",
    "1. the index between 0 and 5 of the most resonant of the six DFT coefficient 1 through 6\n",
    "2. its magnitude\n",
    "3. the inverse entropy of the 6 magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_coeffs, max_mags, inv_entropies = get_most_resonant(mag_phase_mx_dict, )\n",
    "np.column_stack((max_coeffs[EXAMPLE_FNAME][:3],\n",
    "max_mags[EXAMPLE_FNAME][:3],\n",
    "inv_entropies[EXAMPLE_FNAME][:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading major, minor, and tritone correlations\n",
    "\n",
    "This cell loads pickled matrices. To re-compute correlations from pitch-class matrices, use `get_maj_min_coeffs()` for major and minor correlations and `get_ttms()` for tritone-ness matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correl_dict = get_correlations(DATA_FOLDER, long=LONG_FORMAT)\n",
    "test_dict_keys(correl_dict, metadata)\n",
    "correl_dict[EXAMPLE_FNAME].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pickled 9-fold vectors\n",
    "\n",
    "The function is a shortcut for\n",
    "* loading a particular kind of pickled normalized magnitude-phase-matrices\n",
    "* loading pickled tritone, major, and minor coefficients\n",
    "* concatenating them toegther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "norm_params = ('0c', True)\n",
    "ninefold_dict = make_feature_vectors(DATA_FOLDER, norm_params=norm_params, long=LONG_FORMAT)\n",
    "test_dict_keys(ninefold_dict, metadata)\n",
    "ninefold_dict[EXAMPLE_FNAME].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating pentatonic from diatonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "ground_truth_train = pd.read_csv('full_groundtruth_train.csv')\n",
    "penta_dia = ground_truth_train[ground_truth_train['structure'].isin(['penta', 'majmin'])]\n",
    "\n",
    "X_cols = ['coeff1', 'coeff2', 'coeff3', 'coeff4', 'coeff5', 'coeff6', 'major', 'minor', 'tritone']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    penta_dia[X_cols], penta_dia['diatonic'], test_size=0.33, random_state=42\n",
    "    )\n",
    "\n",
    "clf = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "max_coeffs_penta, max_mags_penta, inv_entropies_penta = get_most_resonant_penta_dia(mag_phase_mx_dict, ninefold_dict, clf)\n",
    "np.column_stack((max_coeffs_penta[EXAMPLE_FNAME][:3],\n",
    "max_mags_penta[EXAMPLE_FNAME][:3],\n",
    "inv_entropies_penta[EXAMPLE_FNAME][:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "In this section, a dataframe containing all metrics is compiled. Optional plots and tests can be done by adjusting the parameters of the wrapper function `get_metric` that can be found in `etl.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_metrics = metadata.copy()\n",
    "#metadata_metrics = pd.read_csv('metrics.csv').set_index('fname')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center of mass\n",
    "\n",
    "Computing the center of mass of each coefficient for all the pieces. Uses `mag_phase_mx_dict` as input and outputs the vertical center of mass as a fraction of the height of the wavescape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = [f\"center_of_mass_{i}\" for i in range(1,7)]\n",
    "metadata_metrics = get_metric('center_of_mass', metadata_metrics, \n",
    "                              mag_phase_mx_dict=mag_phase_mx_dict, \n",
    "                              cols=cols, store_matrix=True, \n",
    "                              show_plot=True, save_name='center_of_mass', title='Center of Mass')\n",
    "metadata_metrics.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out some options of the function\n",
    "# 1 unified plot\n",
    "metadata_metrics = get_metric('center_of_mass', metadata_metrics, \n",
    "                              mag_phase_mx_dict=mag_phase_mx_dict,\n",
    "                              cols=cols, store_matrix=True, \n",
    "                              show_plot=True, save_name='center_of_mass', title='Center of Mass',\n",
    "                              unified=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 using ordinal years\n",
    "metadata_metrics = get_metric('center_of_mass', metadata_metrics,\n",
    "                              mag_phase_mx_dict=mag_phase_mx_dict,\n",
    "                              cols=cols, store_matrix=True,\n",
    "                              show_plot=True, save_name='center_of_mass', title='Center of Mass',\n",
    "                              ordinal=True, ordinal_col='years_ordinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot version with ordinal column\n",
    "metadata_metrics = get_metric('center_of_mass', metadata_metrics, \n",
    "                              mag_phase_mx_dict=mag_phase_mx_dict,\n",
    "                              cols=cols, store_matrix=True, \n",
    "                              show_plot=True, save_name='center_of_mass', title='Center of Mass', \n",
    "                              boxplot=True, ordinal=True, ordinal_col='years_periods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 4. testing option\n",
    "metadata_metrics = get_metric('center_of_mass', metadata_metrics,\n",
    "                              mag_phase_mx_dict=mag_phase_mx_dict, cols=cols,\n",
    "                              store_matrix=True, testing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Resonance\n",
    "\n",
    "Computing the mean resonance of each coefficient for all the pieces. Uses `mag_phase_mx_dict` as input and outputs the magnitude resonance of the wavescape for each coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = [f\"mean_resonances_{i}\" for i in range(1,7)]\n",
    "\n",
    "metadata_metrics = get_metric('mean_resonance', metadata_metrics, \n",
    "                              mag_phase_mx_dict=mag_phase_mx_dict,\n",
    "                              cols=cols, store_matrix=True, \n",
    "                              show_plot=True, save_name='mean_resonances', title='Mean Resonance')\n",
    "metadata_metrics.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per period ordinal plot\n",
    "metadata_metrics = get_metric('mean_resonance', metadata_metrics, \n",
    "                              mag_phase_mx_dict=mag_phase_mx_dict,\n",
    "                              cols=cols, store_matrix=True, \n",
    "                              show_plot=False, testing=True, save_name='mean_resonance_per_period', title='Mean Resonance per Period', boxplot=True,\n",
    "                              ordinal=True, ordinal_col='years_periods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Center of Mass \n",
    "#### only on most resonant coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_metrics = metadata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [f\"center_of_mass_{i}\" for i in range(1,7)]\n",
    "metadata_metrics = get_metric('center_of_mass_2', metadata_metrics, \n",
    "                              max_coeffs=max_coeffs,\n",
    "                              max_mags=max_mags,\n",
    "                              cols=cols, store_matrix=True, testing=True, unified=True,\n",
    "                              show_plot=True, save_name='center_of_mass', title='Center of Mass')\n",
    "metadata_metrics.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moment of Inertia\n",
    "\n",
    "Moment of inertia of coefficient $n$ in the summary wavescape: $I(n)=1/N \\sum_{i \\in S(n)} w_i y_i^2$, where N is the total number of nodes in the wavescape, $S(n)$ is the set of the indices of the nodes in the summary wavescapes that are attributed to coefficient $n$ (i.e., where coefficient n is the most prominent among the six), $w_i$ is the weight (opacity) of the $i$-th node in the summary wavescape, and $y_i$ is the vertical coordinate of the $i$-th node in the summary wavescape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = [f\"moments_of_inertia_{i}\" for i in range(1,7)]\n",
    "print(len(cols))\n",
    "metadata_metrics = get_metric('moment_of_inertia', metadata_metrics, \n",
    "                              max_coeffs=max_coeffs,\n",
    "                              max_mags=max_mags,\n",
    "                              cols=cols, store_matrix=True,\n",
    "                              testing=True, \n",
    "                              show_plot=True, save_name='moments_of_inertia', title='Moments of Inertia', unified=True)\n",
    "metadata_metrics.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prevalence of each coefficient\n",
    "\n",
    "Prevalence of coefficient $n$ in a piece: $W(n)=1/N \\sum_{i \\in S(n)} i$ where $N$ is the total number of nodes in the wavescape, $S(n)$ is the set of the indices of the nodes in the summary wavescapes that are attributed to coefficient $n$ (i.e., where coefficient $n$ is the most prominent among the six)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = [f\"percentage_resonances_{i}\" for i in range(1,7)]\n",
    "\n",
    "metadata_metrics = get_metric('percentage_resonance', metadata_metrics, \n",
    "                              max_coeffs=max_coeffs,\n",
    "                              cols=cols, store_matrix=True, testing=True,\n",
    "                              show_plot=True, save_name='percentage_resonance', title='Percentage Resonance', unified=True)\n",
    "metadata_metrics.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# metadata_metrics = get_metric('percentage_resonance', metadata_metrics, \n",
    "#                               max_coeffs=max_coeffs,\n",
    "#                               cols=cols, store_matrix=True, \n",
    "#                               show_plot=True, save_name='percentage_resonance_periods', title='Percentage Resonance (Periods)',  boxplot=True,\n",
    "#                               ordinal=True, ordinal_col='years_periods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to account for the certainty that a certain coefficient is actually the most resonance, we weigh the previous metric by entropy as follows: $W(n)=1/N \\sum_{i \\in S(n)} w_i$ where $N$ is the total number of nodes in the wavescape, $S(n)$ is the set of the indices of the nodes in the summary wavescapes that are attributed to coefficient $n$ (i.e., where coefficient $n$ is the most prominent among the six), and $w_i$ is the weight (opacity) of the $i$-th node in the summary wavescape, in this case, the entropy of $i$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = [f\"percentage_resonances_entropy_{i}\" for i in range(1,7)]\n",
    "\n",
    "metadata_metrics = get_metric('percentage_resonance_entropy', metadata_metrics, \n",
    "                              max_coeffs=max_coeffs,\n",
    "                              inv_entropies=inv_entropies,\n",
    "                              cols=cols, store_matrix=True, \n",
    "                              testing=True,\n",
    "                              show_plot=True, save_name='percentage_resonance_entropy', title='Percentage Resonance (entropy)', unified=True)\n",
    "metadata_metrics.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# metadata_metrics = get_metric('percentage_resonance_entropy', metadata_metrics, \n",
    "#                               max_coeffs=max_coeffs,\n",
    "#                               inv_entropies=inv_entropies,\n",
    "#                               cols=cols, store_matrix=True, \n",
    "#                               show_plot=True, save_name='percentage_resonance_entropy_period', title='Percentage Resonance (entropy period)',  boxplot=True,\n",
    "#                               ordinal=True, ordinal_col='years_periods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata_metrics.to_csv('results/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metadata = pd.read_csv('results/metrics_melted (1).csv')\n",
    "metadata.head()\n",
    "metadata['value_com']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Theoretic Entropy\n",
    "\n",
    "Measure-theoretic entropy: Let $A={A_1,...,A_k}$ be a (finite) partition of a probability space $(X,P(X),)$: the entropy of the partition $A$ is defined as $H(A)= - \\sum_{i} \\mu(A_i) \\log \\mu(A_i)$. We can take $X$ as the support of the wavescape, $A$ as the set of the connected regions in the unified wavescape, and $\\mu(Y)=(area-of-Y)/(area-of-X)$ for any subset $Y$ of the wavescape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# takes quite long\n",
    "cols = 'partition_entropy'\n",
    "### add interaction year length\n",
    "metadata_metrics = get_metric('partition_entropy', metadata_metrics, \n",
    "                              max_coeffs=max_coeffs,\n",
    "                              cols=cols, store_matrix=True, scatter=True, testing=True,\n",
    "                              show_plot=True, save_name='partition_entropy', title='Partition Entropy', unified=True)\n",
    "metadata_metrics.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metadata_metrics_ = metadata_metrics.reset_index()\n",
    "metadata_metrics_['fname'] = metadata_metrics_['index']\n",
    "all_cols = [col for col in list(metadata_metrics_.columns) if col not in ['fname', 'length_qb', 'year', 'last_mc']]\n",
    "metadata_metrics_ = pd.melt(metadata_metrics_, id_vars=['fname', 'length_qb', 'year', 'last_mc'], value_vars=all_cols)    \n",
    "metadata_metrics_.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decreasing magnitude in height\n",
    "\n",
    "The inverse coherence is the slope of the regression line that starts from the magnitude resonance in the summary wavescape at bottom of the wavescape and reaches the one at the top of the wavescape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 'inverse_coherence'\n",
    "metadata_metrics = get_metric('inverse_coherence', metadata_metrics, \n",
    "                              max_mags=max_mags,\n",
    "                              cols=cols, store_matrix=True, \n",
    "                              show_plot=True, save_name='inverse_coherence', title='Inverse Coherence', unified=True, scatter=True)\n",
    "metadata_metrics.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_metrics.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_metrics.to_csv('results/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_metrics.sort_values('inverse_coherence').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mag = max_mags['l123-08_preludes_ondine']\n",
    "#max_coeff = max_coeffs['l108_morceau']\n",
    "np.polyfit((max_mag.shape[1] - np.arange(max_mag.shape[1]))/max_mag.shape[1], np.mean(max_mag, axis=0), 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "ax = sns.regplot(x=(max_mag.shape[1] - np.arange(max_mag.shape[1]))/max_mag.shape[1], y=np.mean(max_mag, axis=0), ci=False)\n",
    "ax.set_title('Regression line. Example: Ondine')\n",
    "ax.set_xlabel('hierarchical height')\n",
    "ax.set_ylabel('mean maximum magnitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/coherence.png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_metrics = get_metric('inverse_coherence', metadata_metrics, \n",
    "                              max_mags=max_mags,\n",
    "                              cols=cols, store_matrix=True, \n",
    "                              show_plot=False, testing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the final metrics for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_metrics.reset_index().to_csv('normalized_coherence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metadata_metrics.reset_index().to_csv('metrics_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6bdddb31d2fb89da9078eb0011314936146baaf4f9e5c99982bea0ddf03884f8"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
